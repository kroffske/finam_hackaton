# üìä –ú–µ—Ç—Ä–∏–∫–∏ –æ—Ü–µ–Ω–∫–∏ ‚Äî –ü–æ–¥—Ä–æ–±–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ

> **–ò—Å—Ç–æ—á–Ω–∏–∫**: `docs/evaluation.md` (–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –º–µ—Ç–æ–¥–∏–∫–∞ –æ—Ü–µ–Ω–∫–∏)

---

## üéØ –ö–∞–∫ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è —Ç–∞—Ä–≥–µ—Ç—ã (—Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ)

### –§–æ—Ä–º—É–ª—ã –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏

**–¢–∞—Ä–≥–µ—Ç—ã** ‚Äî —ç—Ç–æ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º. –û–Ω–∏ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –∏–∑ **–±—É–¥—É—â–∏—Ö —Ü–µ–Ω**:

#### 1. **–î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (Return)** ‚Äî –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã

$$
\text{target\_return\_Nd} = \frac{\text{close}_{t+N}}{\text{close}_t} - 1
$$

–≥–¥–µ:
- $\text{close}_t$ ‚Äî —Ü–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –≤ –¥–µ–Ω—å $t$ (—Ç–µ–∫—É—â–∏–π –¥–µ–Ω—å)
- $\text{close}_{t+N}$ ‚Äî —Ü–µ–Ω–∞ –∑–∞–∫—Ä—ã—Ç–∏—è —á–µ—Ä–µ–∑ $N$ —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π
- $N \in \{1, 20\}$ ‚Äî –≥–æ—Ä–∏–∑–æ–Ω—Ç –ø—Ä–æ–≥–Ω–æ–∑–∞ (1 –¥–µ–Ω—å –∏–ª–∏ 20 –¥–Ω–µ–π)

**–ü—Ä–∏–º–µ—Ä:**
```python
# –î–µ–Ω—å t: close = 81.70
# –î–µ–Ω—å t+1: close = 82.10

target_return_1d = (82.10 / 81.70) - 1 = 0.004896 ‚âà +0.49%
```

#### 2. **–ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ (Direction)** ‚Äî –∑–Ω–∞–∫ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏

$$
\text{target\_direction\_Nd} = \begin{cases}
1, & \text{–µ—Å–ª–∏ } \text{target\_return\_Nd} > 0 \text{ (—Ä–æ—Å—Ç)} \\
0, & \text{–µ—Å–ª–∏ } \text{target\_return\_Nd} \leq 0 \text{ (–ø–∞–¥–µ–Ω–∏–µ –∏–ª–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)}
\end{cases}
$$

**–ü—Ä–∏–º–µ—Ä:**
```python
target_return_1d = 0.004896  # –†–æ—Å—Ç ‚Üí direction = 1
target_return_20d = -0.010962  # –ü–∞–¥–µ–Ω–∏–µ ‚Üí direction = 0
```

---

### –¢–∏–ø—ã –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏

**1. –ù–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (Cumulative Return)** ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∑–∞–¥–∞—á–µ

$$
R_{\text{cum}} = \frac{P_{t+N}}{P_t} - 1
$$

- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç **–æ–±—â–∏–π % –∏–∑–º–µ–Ω–µ–Ω–∏—è** –∑–∞ –ø–µ—Ä–∏–æ–¥
- **–ù–ï –∑–∞–≤–∏—Å–∏—Ç** –æ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
- –ü—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ —Ü–µ–Ω–∞ –≤—ã—Ä–æ—Å–ª–∞ —Å 100 –¥–æ 120, —Ç–æ $R = 0.20 = +20\%$

**2. –°—Ä–µ–¥–Ω–µ–¥–Ω–µ–≤–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (Average Daily Return)** ‚Äî –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è

$$
R_{\text{avg}} = \frac{1}{N} \sum_{i=1}^{N} r_i, \quad \text{–≥–¥–µ } r_i = \frac{P_i - P_{i-1}}{P_{i-1}}
$$

- –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç **—Å—Ä–µ–¥–Ω–µ–µ –¥–Ω–µ–≤–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ**
- –¢—Ä–µ–±—É–µ—Ç –∑–Ω–∞–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —Ü–µ–Ω

**–í –∑–∞–¥–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å!**

---

### –í–∞–∂–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

#### ‚ö†Ô∏è –¢–æ—Ä–≥–æ–≤—ã–µ vs –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã–µ –¥–Ω–∏

- **–¢–æ—Ä–≥–æ–≤—ã–µ –¥–Ω–∏** ‚Äî –¥–Ω–∏ –∫–æ–≥–¥–∞ –±–∏—Ä–∂–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç (–ø–Ω-–ø—Ç, –∏—Å–∫–ª—é—á–∞—è –ø—Ä–∞–∑–¥–Ω–∏–∫–∏)
- **20 —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π ‚âà 1 –º–µ—Å—è—Ü** (–Ω–µ 20 –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –¥–Ω–µ–π!)

```python
# –ü—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ 20 —Ç–æ—Ä–≥–æ–≤—ã—Ö –¥–Ω–µ–π, —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å:
# 2025-04-01 ‚Üí 2025-05-01 (–ø—Ä–∏–º–µ—Ä–Ω–æ 28-30 –∫–∞–ª–µ–Ω–¥–∞—Ä–Ω—ã—Ö –¥–Ω–µ–π)
```

#### ‚ö†Ô∏è –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –Ω–µ –∏–º–µ—é—Ç —Ç–∞—Ä–≥–µ—Ç–æ–≤

–î–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞:
- **–ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞** ‚Üí –Ω–µ—Ç `target_return_1d` (–Ω–µ—Ç –¥–Ω—è $t+1$)
- **–ü–æ—Å–ª–µ–¥–Ω–∏–µ 20 —Å—Ç—Ä–æ–∫** ‚Üí –Ω–µ—Ç `target_return_20d` (–Ω–µ—Ç –¥–Ω—è $t+20$)

```python
# –í train —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –∏–º–µ—é—Ç NaN –∏–ª–∏ —É–¥–∞–ª–µ–Ω—ã
df['target_return_20d'].isna().sum()  # > 0 –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 20 –¥–Ω–µ–π –∫–∞–∂–¥–æ–≥–æ —Ç–∏–∫–µ—Ä–∞
```

#### ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º—É–ª

–ú—ã –ø—Ä–æ–≤–µ—Ä–∏–ª–∏ —á—Ç–æ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–∏ —Ñ–æ—Ä–º—É–ª—ã:

```bash
python scripts/verify_targets.py

# –†–µ–∑—É–ª—å—Ç–∞—Ç:
# ‚úÖ –í—Å–µ —Ç–∞—Ä–≥–µ—Ç—ã –≤—ã—á–∏—Å–ª–µ–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ (—Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ < 1e-06)
# –ú–∞–∫—Å. —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏–µ: 9.99e-17 (–ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –æ–∫—Ä—É–≥–ª–µ–Ω–∏—è float64)
```

---

### –°–≤—è–∑—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏

–ù–∞—à–∏ –º–æ–¥–µ–ª–∏ –¥–æ–ª–∂–Ω—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å 4 –≤–µ–ª–∏—á–∏–Ω—ã:

| –¢–∞—Ä–≥–µ—Ç | –¢–∏–ø | –§–æ—Ä–º–∞—Ç | –ß—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º |
|--------|-----|--------|-------------------|
| `pred_return_1d` | regression | float | –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∑–∞ 1 –¥–µ–Ω—å |
| `pred_return_20d` | regression | float | –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å –∑–∞ 20 –¥–Ω–µ–π |
| `pred_prob_up_1d` | probability | [0, 1] | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –∑–∞ 1 –¥–µ–Ω—å |
| `pred_prob_up_20d` | probability | [0, 1] | –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –∑–∞ 20 –¥–Ω–µ–π |

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** `pred_prob_up` ‚Äî —ç—Ç–æ –ù–ï —Ç–æ –∂–µ —Å–∞–º–æ–µ —á—Ç–æ `target_direction`!
- `target_direction` ‚àà {0, 1} ‚Äî –±–∏–Ω–∞—Ä–Ω—ã–π —Ñ–∞–∫—Ç (–≤—ã—Ä–æ—Å–ª–æ –∏–ª–∏ –Ω–µ—Ç)
- `pred_prob_up` ‚àà [0, 1] ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å 0.7 = "—Å–∫–æ—Ä–µ–µ –≤—ã—Ä–∞—Å—Ç–µ—Ç")

---

## üéØ –ò—Ç–æ–≥–æ–≤–∞—è –º–µ—Ç—Ä–∏–∫–∞ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è

```
Score = 0.7 √ó MAE_norm + 0.3 √ó Brier_norm + 0.1 √ó DA
```

**–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞**: —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –¥–≤—É–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º (1d –∏ 20d)

```
LeaderboardScore = (Score_1d + Score_20d) / 2
```

---

## üìê –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –º–µ—Ç—Ä–∏–∫–∏

### 1. **MAE (Mean Absolute Error)** ‚Äî –¢–æ—á–Ω–æ—Å—Ç—å –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏

$$
\mathrm{MAE} = \frac{1}{M} \sum_{i=1}^{M} \left| y_i - \hat{y}_i \right|
$$

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç:** –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–æ–≥–Ω–æ–∑–∞ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏

**–ï–¥–∏–Ω–∏—Ü—ã:** –¢–µ –∂–µ —á—Ç–æ –∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å (–Ω–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å = 0.05 = 5%, —Ç–æ MAE –º–æ–∂–µ—Ç –±—ã—Ç—å 0.02 = 2%)

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
- **MAE = 0.02** ‚Üí –≤ —Å—Ä–µ–¥–Ω–µ–º –æ—à–∏–±–∞–µ–º—Å—è –Ω–∞ ¬±2% –≤ –ø—Ä–æ–≥–Ω–æ–∑–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
- **–ú–µ–Ω—å—à–µ = –ª—É—á—à–µ** (0 = –∏–¥–µ–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ)

**–ü—Ä–∏–º–µ—Ä:**
```python
y_true = [0.01, -0.02, 0.03]  # –†–µ–∞–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏: +1%, -2%, +3%
y_pred = [0.015, -0.01, 0.025]  # –ü—Ä–æ–≥–Ω–æ–∑—ã: +1.5%, -1%, +2.5%

MAE = (|0.01 - 0.015| + |-0.02 - (-0.01)| + |0.03 - 0.025|) / 3
    = (0.005 + 0.01 + 0.005) / 3
    = 0.00667 ‚âà 0.67%
```

**–ü–æ—á–µ–º—É MAE, –∞ –Ω–µ MSE?**
- –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –∏–º–µ—é—Ç **"—Ç–æ–ª—Å—Ç—ã–µ —Ö–≤–æ—Å—Ç—ã"** (fat tails)
- **MSE** —Å–∏–ª—å–Ω–æ —à—Ç—Ä–∞—Ñ—É–µ—Ç –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏ ‚Üí –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ outliers
- **MAE** —Ä–æ–±–∞—Å—Ç–Ω–µ–µ –∫ –≤—ã–±—Ä–æ—Å–∞–º ‚Üí –ª—É—á—à–µ –æ–±–æ–±—â–∞–µ—Ç—Å—è

---

### 2. **Brier Score** ‚Äî –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π

$$
\mathrm{Brier} = \frac{1}{M} \sum_{i=1}^{M} \left( \mathbf{1}[y_i>0] - p_{\uparrow,i} \right)^2
$$

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç:** –ù–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –∫–∞–ª–∏–±—Ä–æ–≤–∞–Ω–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
- **Brier = 0** ‚Üí –∏–¥–µ–∞–ª—å–Ω–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞
- **Brier = 0.25** ‚Üí –ø–ª–æ—Ö–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ (–∫–∞–∫ —É random classifier)
- **–ú–µ–Ω—å—à–µ = –ª—É—á—à–µ**

**–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞** = "–µ—Å–ª–∏ –º–æ–¥–µ–ª—å –≥–æ–≤–æ—Ä–∏—Ç '–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ 80%', —Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –ª–∏ –≤ 80% —Å–ª—É—á–∞–µ–≤ –±—ã–ª —Ä–æ—Å—Ç?"

**–ü—Ä–∏–º–µ—Ä:**
```python
y_true = [0.01, -0.02, 0.03, 0.05]  # –†–µ–∞–ª—å–Ω—ã–µ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
# –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: [—Ä–æ—Å—Ç, –ø–∞–¥–µ–Ω–∏–µ, —Ä–æ—Å—Ç, —Ä–æ—Å—Ç] = [1, 0, 1, 1]

p_up = [0.6, 0.3, 0.7, 0.8]  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞

Brier = ((1 - 0.6)¬≤ + (0 - 0.3)¬≤ + (1 - 0.7)¬≤ + (1 - 0.8)¬≤) / 4
      = (0.16 + 0.09 + 0.09 + 0.04) / 4
      = 0.095
```

**–•–æ—Ä–æ—à–∞—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞** = –Ω–∞–¥—ë–∂–Ω—ã–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è:
- Risk management (–æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ—Ç–µ—Ä—å)
- Portfolio optimization (allocation –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ confidence)
- Decision making (–∫–æ–≥–¥–∞ —Å—Ç–∞–≤–∏—Ç—å —Å—Ç–æ–ø-–ª–æ—Å—Å?)

---

### 3. **DA (Directional Accuracy)** ‚Äî –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è

$$
\mathrm{DA} = \frac{1}{M} \sum_{i=1}^{M} \mathbf{1}\!\left[\operatorname{sign}(\hat{y}_i) = \operatorname{sign}(y_i)\right]
$$

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç:** –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ —É–≥–∞–¥–∞–Ω–Ω—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π (–∑–Ω–∞–∫ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏)

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
- **DA = 0.5** ‚Üí —Å–ª—É—á–∞–π–Ω–æ–µ —É–≥–∞–¥—ã–≤–∞–Ω–∏–µ (–∫–∞–∫ –º–æ–Ω–µ—Ç–∫–∞)
- **DA = 0.6** ‚Üí —É–≥–∞–¥—ã–≤–∞–µ–º 60% –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π (—Ö–æ—Ä–æ—à–æ!)
- **DA = 0.7+** ‚Üí –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ (—Ä–µ–¥–∫–æ –¥–æ—Å—Ç–∏–∂–∏–º–æ –Ω–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ)
- **–ë–æ–ª—å—à–µ = –ª—É—á—à–µ** (1.0 = –≤—Å–µ–≥–¥–∞ —É–≥–∞–¥—ã–≤–∞–µ–º –∑–Ω–∞–∫)

**–ü—Ä–∏–º–µ—Ä:**
```python
y_true = [0.01, -0.02, 0.03, -0.01]  # –ó–Ω–∞–∫–∏: [+, -, +, -]
y_pred = [0.015, -0.01, 0.005, 0.01]  # –ó–Ω–∞–∫–∏: [+, -, +, +]
#                                       –°–æ–≤–ø–∞–¥–∞—é—Ç: ‚úì  ‚úì  ‚úì  ‚úó

DA = 3 / 4 = 0.75 = 75%
```

**–ü–æ—á–µ–º—É –≤–∞–∂–Ω–∞ DA?**
- –î–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞ –≤–∞–∂–Ω–µ–µ **–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ** —á–µ–º —Ç–æ—á–Ω–∞—è –≤–µ–ª–∏—á–∏–Ω–∞
- –ï—Å–ª–∏ –∑–Ω–∞–µ–º —á—Ç–æ –∞–∫—Ç–∏–≤ –≤—ã—Ä–∞—Å—Ç–µ—Ç, –º–æ–∂–µ–º –∫—É–ø–∏—Ç—å (–¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ–º –Ω–∞—Å–∫–æ–ª—å–∫–æ)
- DA > 50% ‚Üí –µ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏–ª–∞!

---

### 4. **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ Baseline**

$$
MAE_{\mathrm{norm}} = 1 - \frac{\mathrm{MAE}}{\mathrm{MAE}_{\mathrm{base}}}, \qquad Brier_{\mathrm{norm}} = 1 - \frac{\mathrm{Brier}}{\mathrm{Brier}_{\mathrm{base}}}
$$

**–ß—Ç–æ –∏–∑–º–µ—Ä—è–µ—Ç:** –ù–∞—Å–∫–æ–ª—å–∫–æ –≤—ã –ª—É—á—à–µ –ø—Ä–æ—Å—Ç–æ–≥–æ Momentum Baseline

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
- **MAE_norm = 0** ‚Üí —Ç–∞–∫–æ–π –∂–µ –∫–∞–∫ baseline
- **MAE_norm > 0** ‚Üí –ª—É—á—à–µ baseline (–∂–µ–ª–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç!)
- **MAE_norm < 0** ‚Üí —Ö—É–∂–µ baseline (–Ω—É–∂–Ω–æ —É–ª—É—á—à–∞—Ç—å)

**–ü—Ä–∏–º–µ—Ä:**
```python
# –í–∞—à–∞ –º–æ–¥–µ–ª—å:
MAE_model = 0.016846
Brier_model = 0.263079

# Baseline (Momentum):
MAE_baseline = 0.020005
Brier_baseline = 0.262271

# –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:
MAE_norm = 1 - (0.016846 / 0.020005) = 1 - 0.842 = 0.158 = +15.8% —É–ª—É—á—à–µ–Ω–∏–µ
Brier_norm = 1 - (0.263079 / 0.262271) = 1 - 1.003 = -0.003 = -0.3% —É—Ö—É–¥—à–µ–Ω–∏–µ
```

---

## üßÆ –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Score

```
Score = 0.7 √ó MAE_norm + 0.3 √ó Brier_norm + 0.1 √ó DA
```

**–í–µ—Å–∞:**
- **70%** ‚Äî —Ç–æ—á–Ω–æ—Å—Ç—å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ (MAE) ‚Äî —Å–∞–º–æ–µ –≤–∞–∂–Ω–æ–µ!
- **30%** ‚Äî –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π (Brier) ‚Äî –≤–∞–∂–Ω–æ –¥–ª—è risk management
- **10%** ‚Äî —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (DA) ‚Äî –±–æ–Ω—É—Å –∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∑–Ω–∞–∫

**–ü–æ—á–µ–º—É —Ç–∞–∫–∏–µ –≤–µ—Å–∞?**
- **MAE** ‚Äî –æ—Å–Ω–æ–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ (magnitude of returns matters most)
- **Brier** ‚Äî –≤–∞–∂–Ω–∞ –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏ (–Ω–∞–¥—ë–∂–Ω—ã–µ probabilities = better decisions)
- **DA** ‚Äî –ø—Ä–∏—è—Ç–Ω—ã–π –±–æ–Ω—É—Å (–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∂–Ω–æ, –Ω–æ magnitude –≤–∞–∂–Ω–µ–µ)

**–ü—Ä–∏–º–µ—Ä —Ä–∞—Å—á—ë—Ç–∞:**
```python
# –ò–∑ –Ω–∞—à–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ (1d):
MAE_norm = 0.158243
Brier_norm = -0.003076  # –ß—É—Ç—å —Ö—É–∂–µ baseline
DA = 0.4864

Score_1d = 0.7 √ó 0.158243 + 0.3 √ó (-0.003076) + 0.1 √ó 0.4864
         = 0.110770 + (-0.000923) + 0.048640
         = 0.158487
```

---

## ‚ùì FAQ: –ü–æ—á–µ–º—É LightGBM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–ª—å–∫–æ MAE?

### –í–æ–ø—Ä–æ—Å
> –í –º–µ—Ç—Ä–∏–∫–µ —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è (MAE + Brier + DA), –ø–æ—á–µ–º—É LightGBM –æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ MAE?

### –û—Ç–≤–µ—Ç

**–ú—ã –æ–±—É—á–∞–µ–º 4 –û–¢–î–ï–õ–¨–ù–´–• –º–æ–¥–µ–ª–∏ –¥–ª—è 4 —Ç–∞—Ä–≥–µ—Ç–æ–≤:**

```python
# 1. –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å 1d ‚Üí regression, MAE loss
model_return_1d = LGBMRegressor(objective='mae')

# 2. –î–æ—Ö–æ–¥–Ω–æ—Å—Ç—å 20d ‚Üí regression, MAE loss
model_return_20d = LGBMRegressor(objective='mae')

# 3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ 1d ‚Üí classification, binary loss
model_prob_up_1d = LGBMClassifier(objective='binary')

# 4. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ 20d ‚Üí classification, binary loss
model_prob_up_20d = LGBMClassifier(objective='binary')
```

### Mapping: Model ‚Üí Metric

| Model | Objective | Optimizes | Evaluated with |
|-------|-----------|-----------|----------------|
| `model_return_1d` | `mae` | Minimize MAE | **MAE_1d** |
| `model_return_20d` | `mae` | Minimize MAE | **MAE_20d** |
| `model_prob_up_1d` | `binary` | Maximize log-likelihood | **Brier_1d**, **DA_1d** |
| `model_prob_up_20d` | `binary` | Maximize log-likelihood | **Brier_20d**, **DA_20d** |

### –ü–æ—á–µ–º—É –Ω–µ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π loss?

**1. –†–∞–∑–Ω—ã–µ —Ç–∏–ø—ã —Ç–∞—Ä–≥–µ—Ç–æ–≤:**
- Return ‚Üí regression (continuous)
- Probability ‚Üí classification (binary)
- Direction ‚Üí derived from return prediction (sign)

**2. –†–∞–∑–Ω—ã–µ —à–∫–∞–ª—ã:**
- MAE ‚àà [0, +‚àû] (–¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏: ¬±20%)
- Brier ‚àà [0, 1] (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏: 0-100%)
- DA ‚àà [0, 1] (accuracy)

**3. –ú–æ–¥—É–ª—å–Ω–æ—Å—Ç—å:**
- –ú–æ–∂–Ω–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ —É–ª—É—á—à–∞—Ç—å –∫–∞–∂–¥—É—é –º–æ–¥–µ–ª—å
- –ú–æ–∂–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞—Ä–≥–µ—Ç–æ–≤
- –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å ensemble/stacking

### –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞ = Evaluation, –Ω–µ Training

**Score** –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è **–ü–û–°–õ–ï –æ–±—É—á–µ–Ω–∏—è** –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π:

```python
# –ü–û–°–õ–ï –æ–±—É—á–µ–Ω–∏—è –≤—Å–µ—Ö 4 –º–æ–¥–µ–ª–µ–π:
preds = model.predict(X_test)

# Evaluation:
metrics = evaluate_predictions(
    y_true_1d, y_true_20d,
    preds['pred_return_1d'], preds['pred_return_20d'],
    preds['pred_prob_up_1d'], preds['pred_prob_up_20d']
)

# –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π:
score = 0.7 * metrics['mae_norm'] + 0.3 * metrics['brier_norm'] + 0.1 * metrics['da']
```

**–≠—Ç–æ –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è ranking/leaderboard, –Ω–µ loss function –¥–ª—è gradient descent!**

---

## üî¨ –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã

### –£–ª—É—á—à–µ–Ω–∏–µ MAE:
- –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–µ features (cross-sectional, interactions)
- Ensemble –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
- Tune hyperparameters (learning_rate, max_depth)

### –£–ª—É—á—à–µ–Ω–∏–µ Brier:
- **Calibration!** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `CalibratedClassifierCV`
- Platt scaling –¥–ª—è post-hoc –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
- –û—Ç–¥–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è probabilities (–Ω–µ —á–µ—Ä–µ–∑ sigmoid –æ—Ç returns)

### –£–ª—É—á—à–µ–Ω–∏–µ DA:
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Momentum baseline –¥–ª—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π (—É –Ω–µ–≥–æ DA > 50%)
- Ensemble: LightGBM –¥–ª—è magnitude, Momentum –¥–ª—è direction
- Assymetric loss functions (–±–æ–ª—å—à–µ —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)

---

## üìö –°—Å—ã–ª–∫–∏

- **MAE**: https://en.wikipedia.org/wiki/Mean_absolute_error
- **Brier Score**: https://en.wikipedia.org/wiki/Brier_score
- **Directional Accuracy**: https://en.wikipedia.org/wiki/Confusion_matrix#Definition
- **Calibration**: https://scikit-learn.org/stable/modules/calibration.html

---

## üí° Takeaways

1. ‚úÖ **3 –º–µ—Ç—Ä–∏–∫–∏, 4 –º–æ–¥–µ–ª–∏** ‚Äî –∫–∞–∂–¥–∞—è –º–æ–¥–µ–ª—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç —Å–≤–æ–π —Ç–∞—Ä–≥–µ—Ç
2. ‚úÖ **MAE = accuracy**, **Brier = calibration**, **DA = direction**
3. ‚úÖ **Score = evaluation metric**, –Ω–µ training loss
4. ‚úÖ **–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è vs baseline** –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ
5. ‚úÖ **70% –≤–µ—Å–∞ –Ω–∞ MAE** ‚Üí —Ç–æ—á–Ω–æ—Å—Ç—å –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ —Å–∞–º–∞—è –≤–∞–∂–Ω–∞—è

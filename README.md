# ML Pipeline –¥–ª—è FORECAST —Ö–∞–∫–∞—Ç–æ–Ω–∞

## üìã –û–±–∑–æ—Ä

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ML –ø–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏—è FORECAST. –ü–∞–π–ø–ª–∞–π–Ω –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:

1. **–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** ‚Äî –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
2. **–°–∫–æ—Ä–æ—Å—Ç—å –∏—Ç–µ—Ä–∞—Ü–∏–π** ‚Äî preprocessed –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
3. **–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞** ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
4. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline** ‚Äî normalized scores –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ Momentum

## üèóÔ∏è –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

```
finam/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/participants/          # –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_candles.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_news.csv         # NEW: –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è —Ñ–∏—á
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_news.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ public_test_candles.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ private_test_candles.csv
‚îÇ   ‚îú‚îÄ‚îÄ preprocessed/              # –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.parquet          # train split —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val.parquet            # validation split
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test.parquet           # test split
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ public_test.parquet    # NEW: preprocessed public test
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ private_test.parquet   # NEW: preprocessed private test
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ metadata.json          # –º–µ—Ç–∞–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ baseline_metrics.json      # NEW: —ç—Ç–∞–ª–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ Momentum
‚îÇ
‚îú‚îÄ‚îÄ outputs/                       # —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ experiments_log.csv        # NEW: —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ YYYY-MM-DD_HH-MM-SS_<name>/
‚îÇ       ‚îú‚îÄ‚îÄ config.yaml            # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
‚îÇ       ‚îú‚îÄ‚îÄ model_*.pkl            # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏
‚îÇ       ‚îú‚îÄ‚îÄ metrics.json           # NEW: –º–µ—Ç—Ä–∏–∫–∏ train/val/test
‚îÇ       ‚îú‚îÄ‚îÄ feature_importance.csv # –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
‚îÇ       ‚îú‚îÄ‚îÄ predictions_val.csv    # –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ val
‚îÇ       ‚îú‚îÄ‚îÄ submission_public.csv  # NEW: submission –¥–ª—è public test
‚îÇ       ‚îî‚îÄ‚îÄ submission_private.csv # NEW: submission –¥–ª—è private test
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ 1_prepare_data.py          # –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ + split + news + public/private
‚îÇ   ‚îú‚îÄ‚îÄ 2_train_model.py           # –æ–±—É—á–µ–Ω–∏–µ —Å train/val/test –æ—Ü–µ–Ω–∫–æ–π
‚îÇ   ‚îú‚îÄ‚îÄ 3_evaluate.py              # –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏
‚îÇ   ‚îú‚îÄ‚îÄ 4_generate_submission.py   # NEW: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è submission —Ñ–∞–π–ª–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ train_baseline.py          # NEW: –æ–±—É—á–µ–Ω–∏–µ Momentum baseline
‚îÇ   ‚îú‚îÄ‚îÄ compute_baseline_metrics.py # NEW: –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ baseline
‚îÇ   ‚îú‚îÄ‚îÄ collect_experiments.py     # NEW: —Å–±–æ—Ä –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
‚îÇ   ‚îî‚îÄ‚îÄ compare_baseline_lgbm.py   # —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
‚îÇ
‚îî‚îÄ‚îÄ src/finam/
    ‚îú‚îÄ‚îÄ features.py                # technical indicators
    ‚îú‚îÄ‚îÄ features_news.py           # NEW: news features
    ‚îú‚îÄ‚îÄ model.py                   # –º–æ–¥–µ–ª–∏ (LightGBM, Momentum)
    ‚îú‚îÄ‚îÄ metrics.py                 # –º–µ—Ç—Ä–∏–∫–∏ + normalized scores
    ‚îî‚îÄ‚îÄ evaluate.py                # —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
```

## üöÄ Workflow

### –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö (–æ–¥–∏–Ω —Ä–∞–∑)

```bash
python scripts/1_prepare_data.py
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç `train_candles.csv` –∏ `train_news.csv`
- –°–æ–∑–¥–∞–µ—Ç 40+ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
- **NEW:** –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Ñ–∏—á–∏ (news_count_1d/7d/30d_lag)
- –†–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ **train/val/test** (70%/15%/15% –ø–æ –≤—Ä–µ–º–µ–Ω–∏)
- **NEW:** –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç `public_test_candles.csv` –∏ `private_test_candles.csv` —Å —Ç–µ–º–∏ –∂–µ —Ñ–∏—á–∞–º–∏
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ `data/preprocessed/*.parquet`

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
data/preprocessed/
‚îú‚îÄ‚îÄ train.parquet        # 16,179 rows (2020-06-19 to 2023-11-21)
‚îú‚îÄ‚îÄ val.parquet          #  3,469 rows (2023-11-22 to 2024-08-12)
‚îú‚îÄ‚îÄ test.parquet         #  3,470 rows (2024-08-13 to 2025-04-15)
‚îú‚îÄ‚îÄ public_test.parquet  #    378 rows (2025-04-16 to 2025-05-09) NEW
‚îú‚îÄ‚îÄ private_test.parquet #    399 rows (2025-05-10 to ...) NEW
‚îî‚îÄ‚îÄ metadata.json        # –∫–æ–Ω—Ñ–∏–≥ + 43 features (–≤–∫–ª—é—á–∞—è 3 –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö)
```

**–û–ø—Ü–∏–∏:**
```bash
python scripts/1_prepare_data.py --train-ratio 0.7 --val-ratio 0.15
python scripts/1_prepare_data.py --windows 5 20 --no-cross-sectional
```

---

### –®–∞–≥ 2: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ baseline –º–µ—Ç—Ä–∏–∫ (–æ–¥–∏–Ω —Ä–∞–∑)

```bash
python scripts/compute_baseline_metrics.py
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –í—ã—á–∏—Å–ª—è–µ—Ç Momentum Baseline –Ω–∞ train/val/test
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ `data/baseline_metrics.json`
- –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è normalized scores –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```json
{
  "train": {"mae_1d": 0.018376, "mae_20d": 0.085435, ...},
  "val": {"mae_1d": 0.013632, "mae_20d": 0.062087, ...},
  "test": {"mae_1d": 0.020728, "mae_20d": 0.096072, ...}
}
```

---

### –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ baseline (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)

```bash
python scripts/train_baseline.py --exp-name momentum_baseline
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –û–±—É—á–∞–µ—Ç Momentum Baseline –∫–∞–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ `outputs/` —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ train/val/test
- –ü–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Å LightGBM

---

### –®–∞–≥ 4: –û–±—É—á–µ–Ω–∏–µ LightGBM –º–æ–¥–µ–ª–∏

```bash
# –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å –Ω–æ–≤–æ—Å—Ç–Ω—ã–º–∏ —Ñ–∏—á–∞–º–∏
python scripts/2_train_model.py --exp-name lgbm_with_news --model-type lightgbm

# –° –∫–∞–ª–∏–±—Ä–æ–≤–∫–æ–π (—É–ª—É—á—à–∞–µ—Ç Brier score!)
python scripts/2_train_model.py --exp-name lgbm_calibrated --model-type lightgbm --calibrate

# –° –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python scripts/2_train_model.py --exp-name lgbm_tuned \
    --model-type lightgbm \
    --n-estimators 1000 \
    --learning-rate 0.01 \
    --max-depth 8 \
    --calibrate
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç preprocessed –¥–∞–Ω–Ω—ã–µ (–≤–∫–ª—é—á–∞—è –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Ñ–∏—á–∏)
- –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å
- **NEW:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–∞ train/val/test
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ `outputs/<timestamp>_<exp_name>/`:
  - –ú–æ–¥–µ–ª–∏ (*.pkl)
  - –ö–æ–Ω—Ñ–∏–≥ (config.yaml)
  - –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è train/val/test (metrics.json)
  - Feature importance (–¥–ª—è LightGBM)

**–ü—Ä–∏–º–µ—Ä –≤—ã–≤–æ–¥–∞:**
```
TEST METRICS:
  MAE 1d:  0.017312
  MAE 20d: 0.089794
  Brier 1d:  0.263401
  Brier 20d: 0.297536
  DA 1d:  0.4914 (49.14%)
  DA 20d: 0.5014 (50.14%)
```

---

### –®–∞–≥ 5: –°–±–æ—Ä –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```bash
python scripts/collect_experiments.py
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –≤—Å–µ—Ö –ø–∞–ø–æ–∫ `outputs/`
- –í—ã—á–∏—Å–ª—è–µ—Ç **normalized scores** –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ `experiments_log.csv`

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
```
TOP EXPERIMENTS (by test_score_total)
         exp_name model_type  test_mae_1d  test_mae_20d  test_score_total
   lgbm_with_news   lightgbm     0.017312      0.089794          0.105470 ‚úì
momentum_baseline   momentum     0.020728      0.096072          0.050504
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
python -c "import pandas as pd; df = pd.read_csv('experiments_log.csv'); print(df.sort_values('test_score_total', ascending=False))"

# –§–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø–æ –º–æ–¥–µ–ª–∏
python -c "import pandas as pd; df = pd.read_csv('experiments_log.csv'); print(df[df['model_type']=='lightgbm'].sort_values('test_score_total', ascending=False))"
```

---

### –®–∞–≥ 6: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è submission –¥–ª—è public/private —Ç–µ—Å—Ç–æ–≤

```bash
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è submission –∏–∑ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
python scripts/4_generate_submission.py --run-id 2025-10-03_23-41-15_lgbm_with_news

# –° –∫–∞—Å—Ç–æ–º–Ω–æ–π output –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–µ–π
python scripts/4_generate_submission.py --run-id <run_id> --output-dir submissions/
```

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏–∑ `outputs/<run_id>/`
- –ó–∞–≥—Ä—É–∂–∞–µ—Ç preprocessed `public_test.parquet` –∏ `private_test.parquet`
- –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–æ–≤
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ `outputs/<run_id>/`:
  - `submission_public.csv`
  - `submission_private.csv`

**–§–æ—Ä–º–∞—Ç submission —Ñ–∞–π–ª–æ–≤:**
```csv
ticker,begin,pred_return_1d,pred_return_20d,pred_prob_up_1d,pred_prob_up_20d
AFLT,2025-04-16,0.012345,-0.023456,0.543210,0.456789
AFLT,2025-04-17,-0.001234,0.045678,0.498765,0.567890
...
```

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç—å `python scripts/1_prepare_data.py` –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è `public_test.parquet` –∏ `private_test.parquet`
- –ú–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–∂–µ –æ–±—É—á–µ–Ω–∞ (–µ—Å—Ç—å —Ñ–∞–π–ª—ã model*.pkl –≤ outputs/<run_id>/)

---

### –®–∞–≥ 7: –û—Ü–µ–Ω–∫–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

```bash
# –û—Ü–µ–Ω–∫–∞ –Ω–∞ test –¥–∞–Ω–Ω—ã—Ö
python scripts/3_evaluate.py --exp-dir 2025-10-03_23-41-15_lgbm_with_news --data test

# –° —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ—Ç—á–µ—Ç–∞
python scripts/3_evaluate.py --exp-dir 2025-10-03_23-41-15_lgbm_with_news --data test --save-report
```

---

## üìä –ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è

### 1. –ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Ñ–∏—á–∏

**–î–æ–±–∞–≤–ª–µ–Ω—ã –≤ `features_news.py`:**
- `news_count_1d_lag` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–µ–Ω—å
- `news_count_7d_lag` ‚Äî –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
- `news_count_30d_lag` ‚Äî –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π

**–í–ê–ñ–ù–û:** –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π lag –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è data leakage
- –ù–æ–≤–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–æ `t-1`
- –î–ª—è —Å–≤–µ—á–µ–π –¥–Ω—è `t` –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –¥–æ `t-1`

**Feature Importance:**
```
1. news_count_30d_lag  ‚Äî 1007.5 ü•á
2. news_count_7d_lag   ‚Äî 907.0  ü•à
3. ma_5d               ‚Äî 589.25
```

### 2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ test

**–î–æ:**
- –û—Ü–µ–Ω–∫–∞ —Ç–æ–ª—å–∫–æ –Ω–∞ train/val
- Test –º–µ—Ç—Ä–∏–∫–∏ –Ω—É–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –≤—Ä—É—á–Ω—É—é

**–ü–æ—Å–ª–µ:**
- `2_train_model.py` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –Ω–∞ test
- –í—Å–µ –º–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ `metrics.json`

```json
{
  "train": {...},
  "val": {...},
  "test": {
    "mae_1d": 0.017312,
    "mae_20d": 0.089794,
    ...
  }
}
```

### 3. –°–∏—Å—Ç–µ–º–∞ —Ç—Ä–µ–∫–∏–Ω–≥–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**–ù–æ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞:**
1. **Baseline metrics** ‚Äî —ç—Ç–∞–ª–æ–Ω –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
2. **–ê–≤—Ç–æ—Å–±–æ—Ä –∏–∑ outputs/** ‚Äî –≤—Å–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã –≤ –æ–¥–Ω–æ–π —Ç–∞–±–ª–∏—Ü–µ
3. **Normalized scores** ‚Äî Score = 0.7√óMAE_norm + 0.3√óBrier_norm + 0.1√óDA

**experiments_log.csv:**
```csv
run_id,exp_name,model_type,test_mae_1d,test_mae_20d,test_score_total
2025-10-03_23-41-15_lgbm_with_news,lgbm_with_news,lightgbm,0.017312,0.089794,0.105470
2025-10-03_23-39-26_momentum_baseline,momentum_baseline,momentum,0.020728,0.096072,0.050504
```

### 4. Normalized Score

**–§–æ—Ä–º—É–ª–∞:**
```python
Score = 0.7 √ó MAE_norm + 0.3 √ó Brier_norm + 0.1 √ó DA

–≥–¥–µ:
  MAE_norm = 1 - (model_MAE / baseline_MAE)
  Brier_norm = 1 - (model_Brier / baseline_Brier)
  DA = directional_accuracy (–±–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
```

**–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:**
- **Score > 0** ‚Äî –º–æ–¥–µ–ª—å –ª—É—á—à–µ baseline
- **Score = 0** ‚Äî –º–æ–¥–µ–ª—å —Ä–∞–≤–Ω–∞ baseline
- **Score < 0** ‚Äî –º–æ–¥–µ–ª—å —Ö—É–∂–µ baseline

---

## üìà –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

### –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π (TEST)

| –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç | Model | MAE 1d | MAE 20d | Brier 1d | Brier 20d | DA 1d | DA 20d | **Score** |
|------------|-------|---------|---------|----------|-----------|-------|--------|-----------|
| **lgbm_with_news** | LightGBM | 0.0173 | 0.0898 | 0.263 | 0.298 | 49.1% | 50.1% | **0.1055** ü•á |
| momentum_baseline | Momentum | 0.0207 | 0.0961 | 0.263 | 0.256 | 51.7% | 49.3% | 0.0505 |

### –£–ª—É—á—à–µ–Ω–∏–µ vs Baseline

**LightGBM —Å –Ω–æ–≤–æ—Å—Ç—è–º–∏:**
- ‚úÖ **MAE 1d**: +16.5% –ª—É—á—à–µ (0.0207 ‚Üí 0.0173)
- ‚úÖ **MAE 20d**: +6.6% –ª—É—á—à–µ (0.0961 ‚Üí 0.0898)
- ‚ùå **Brier 1d**: -0.2% (–ø–æ—á—Ç–∏ —Ä–∞–≤–Ω–æ)
- ‚ùå **Brier 20d**: -16.2% (—Ö—É–∂–µ –Ω–∞ –¥–ª–∏–Ω–Ω–æ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ)
- ‚ùå **DA 1d**: -5.0% (—Ö—É–∂–µ —É–≥–∞–¥—ã–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ)
- ‚úÖ **DA 20d**: +1.7% (–ª—É—á—à–µ –Ω–∞ –¥–ª–∏–Ω–Ω–æ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–µ)
- üéØ **Total Score**: **+109%** –ª—É—á—à–µ baseline!

**–í—ã–≤–æ–¥—ã:**
1. ‚úÖ –ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Ñ–∏—á–∏ –û–ß–ï–ù–¨ –≤–∞–∂–Ω—ã (—Ç–æ–ø-2 –ø–æ importance)
2. ‚úÖ LightGBM —Ç–æ—á–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–µ–ª–∏—á–∏–Ω—É –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
3. ‚ùå Momentum –ª—É—á—à–µ —É–≥–∞–¥—ã–≤–∞–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ 1d
4. üîÑ –ù—É–∂–Ω–∞ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è Brier –Ω–∞ 20d

---

## üî¨ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏

### 1. –£–ª—É—á—à–µ–Ω–∏–µ Brier Score –Ω–∞ 20d

**–ü—Ä–æ–±–ª–µ–º–∞:** Brier 20d —Ö—É–∂–µ baseline –Ω–∞ 16%

**–†–µ—à–µ–Ω–∏—è:**
```bash
# –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∫–∞–ª–∏–±—Ä–æ–≤–∫—É
python scripts/2_train_model.py --exp-name lgbm_news_calibrated --calibrate

# –û—Ç–¥–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è probabilities
# TODO: –¥–æ–±–∞–≤–∏—Ç—å --separate-prob-model
```

### 2. Ensemble –¥–ª—è Directional Accuracy

**–ò–¥–µ—è:** –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å LightGBM (returns) + Momentum (direction)
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å LightGBM –¥–ª—è –≤–µ–ª–∏—á–∏–Ω—ã, Momentum –¥–ª—è –∑–Ω–∞–∫–∞
pred_magnitude = lightgbm.predict_return()
pred_sign = momentum.predict_direction()

final_pred = abs(pred_magnitude) * pred_sign
```

### 3. –£–ª—É—á—à–µ–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Ñ–∏—á

**–¢–µ–∫—É—â–∏–µ:** –¢–æ–ª—å–∫–æ count (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π)

**–ü–ª–∞–Ω—ã:**
- Sentiment analysis (positive/negative/neutral)
- Topic modeling (–∫–∞–∫–∏–µ —Ç–µ–º—ã –æ–±—Å—É–∂–¥–∞—é—Ç—Å—è)
- Entity extraction (–∫–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è)

```python
# TODO: –¥–æ–±–∞–≤–∏—Ç—å –≤ features_news.py
def add_sentiment_features(candles_df, news_df):
    # VADER –∏–ª–∏ FinBERT –¥–ª—è sentiment
    pass
```

### 4. Feature Selection

**–¢–æ–ø-20 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:**
```
news_count_30d_lag    1007.5
news_count_7d_lag      907.0
ma_5d                  589.25
volatility_20d         562.0
log_volume             534.25
```

–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –æ–±—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–æ–ø-K:
```bash
# TODO: –¥–æ–±–∞–≤–∏—Ç—å --top-features
python scripts/2_train_model.py --exp-name lgbm_top20 --top-features 20
```

### 5. Cross-validation –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤

**Purged K-Fold:**
- –£—á–∏—Ç—ã–≤–∞—Ç—å overlap –≤ —Ç–∞—Ä–≥–µ—Ç–∞—Ö (20-day targets –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å gap –º–µ–∂–¥—É —Ñ–æ–ª–¥–∞–º–∏

```python
# TODO: –¥–æ–±–∞–≤–∏—Ç—å –≤ src/finam/cv.py
from finam.cv import purged_kfold_cv
```

---

## üí° –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –ë—ã—Å—Ç—Ä–æ–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ

```bash
# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ (–æ–¥–∏–Ω —Ä–∞–∑)
python scripts/1_prepare_data.py

# 2. –í—ã—á–∏—Å–ª–∏—Ç—å baseline (–æ–¥–∏–Ω —Ä–∞–∑)
python scripts/compute_baseline_metrics.py
python scripts/train_baseline.py

# 3. –û–±—É—á–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π
python scripts/2_train_model.py --exp-name lgbm_100trees --n-estimators 100
python scripts/2_train_model.py --exp-name lgbm_500trees --n-estimators 500
python scripts/2_train_model.py --exp-name lgbm_calibrated --calibrate

# 4. –°–æ–±—Ä–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
python scripts/collect_experiments.py

# 5. –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–æ–ø —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã
cat outputs/experiments_log.csv | column -t -s, | head -5
```

### –ê–Ω–∞–ª–∏–∑ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

```bash
# –¢–æ–ø-5 –ª—É—á—à–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤
python -c "
import pandas as pd
df = pd.read_csv('outputs/experiments_log.csv')
print(df[['exp_name', 'test_score_total']].sort_values('test_score_total', ascending=False).head())
"

# –°—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
python -c "
import pandas as pd
df = pd.read_csv('outputs/experiments_log.csv')
exp1 = df[df['exp_name'] == 'lgbm_with_news'].iloc[0]
exp2 = df[df['exp_name'] == 'momentum_baseline'].iloc[0]
print('Experiment 1:', exp1['test_score_total'])
print('Experiment 2:', exp2['test_score_total'])
print('Improvement:', (exp1['test_score_total'] - exp2['test_score_total']) / exp2['test_score_total'] * 100, '%')
"
```

### –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞

```bash
# –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
python -c "
import pandas as pd
df = pd.read_csv('outputs/experiments_log.csv')
best = df.loc[df['test_score_total'].idxmax()]
print('Best experiment:', best['run_id'])
print('Config:', f\"outputs/{best['run_id']}/config.yaml\")
"

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –∫–æ–Ω—Ñ–∏–≥
cat outputs/<best_run_id>/config.yaml

# –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å —Å —Ç–µ–º–∏ –∂–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
python scripts/2_train_model.py \
    --exp-name best_model_v2 \
    --model-type lightgbm \
    --n-estimators <...> \
    --learning-rate <...>
```

---

## üéØ –î–ª—è —Ö–∞–∫–∞—Ç–æ–Ω–∞: Final Submission Pipeline

### 1. –í—ã–±–æ—Ä –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏

```bash
# –ù–∞–π—Ç–∏ –ª—É—á—à–∏–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –ø–æ test_score_total
python scripts/collect_experiments.py

# –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ experiments_log.csv
head -2 outputs/experiments_log.csv | column -t -s,
```

### 2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è submission

```bash
# TODO: —Å–æ–∑–¥–∞—Ç—å scripts/4_generate_submission.py
python scripts/4_generate_submission.py \
    --model-dir outputs/2025-10-03_23-41-15_lgbm_with_news/ \
    --test-data data/raw/participants/public_test_candles.csv \
    --output submission.csv
```

### 3. –ü—Ä–æ–≤–µ—Ä–∫–∞

```bash
# –£–±–µ–¥–∏—Ç—å—Å—è —á—Ç–æ submission –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω
python scripts/verify_submission.py submission.csv
```

---

## üìö –†–µ—Ñ–µ—Ä–µ–Ω—Å—ã

- **CLAUDE.md** ‚Äî –æ–±—â–∏–µ guidelines –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
- **docs/METRICS.md** ‚Äî –æ–ø–∏—Å–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ (MAE, Brier, DA, Score)
- **docs/evaluation.md** ‚Äî —Ñ–æ—Ä–º—É–ª—ã –æ—Ü–µ–Ω–∫–∏
- **SESSION.md** ‚Äî –ª–æ–≥ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏
- **outputs/experiments_log.csv** ‚Äî –∏—Å—Ç–æ—Ä–∏—è –≤—Å–µ—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

---

## üîë –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã

1. **–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å** ‚Äî –∫–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å config + metrics
2. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline** ‚Äî normalized scores –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —É–ª—É—á—à–µ–Ω–∏–µ
3. **–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è** ‚Äî collect_experiments.py —Å–æ–±–∏—Ä–∞–µ—Ç –≤—Å—ë –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
4. **Data leakage protection** ‚Äî –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º lag
5. **–ë—ã—Å—Ç—Ä—ã–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏** ‚Äî preprocessed –¥–∞–Ω–Ω—ã–µ –¥–ª—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤

**–ì–ª–∞–≤–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ:** –ö–∞–∂–¥—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ `outputs/experiments_log.csv` —Å normalized score!

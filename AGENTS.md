# AI Agent Guidelines - finam FORECAST

**Goal:** –ë—ã—Å—Ç—Ä–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è —Ö–∞–∫–∞—Ç–æ–Ω–∞. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å—Ç–æ—Ç–∞, –º–∏–Ω–∏–º—É–º dependencies, –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –∏—Ç–µ—Ä–∞—Ü–∏–π.

---

## üìã Quick Checklist

- ‚úÖ **–ü—Ä–æ—Å—Ç–æ—Ç–∞**: –û–¥–∏–Ω —Ñ–∞–π–ª = –æ–¥–Ω–∞ –∑–∞–¥–∞—á–∞. –ë–µ–∑ overengineering.
- ‚úÖ **Baseline First**: –°–Ω–∞—á–∞–ª–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ—Å—Ç–æ–µ, –ø–æ—Ç–æ–º —É–ª—É—á—à–∞–µ–º.
- ‚úÖ **Quality**: `ruff check --fix && ruff format` –ø–µ—Ä–µ–¥ –∫–æ–º–º–∏—Ç–æ–º.
- ‚úÖ **Colab Ready**: –ú–æ–∂–Ω–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —á–µ—Ä–µ–∑ `pip install git+https://...`
- ‚úÖ **Explicit Args**: –§—É–Ω–∫—Ü–∏–∏ —Å —è–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏, –±–µ–∑ Hydra/configs.

---

## üéØ –ó–∞–¥–∞—á–∞ FORECAST (–∫—Ä–∞—Ç–∫–æ)

**Input:** –¶–µ–Ω—ã –∏ –Ω–æ–≤–æ—Å—Ç–∏ –¥–æ –¥–Ω—è `t` –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ
**Output:** –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–∞:
- `pred_return_1d` ‚Äî –ø—Ä–æ–≥–Ω–æ–∑ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –Ω–∞ 1 –¥–µ–Ω—å
- `pred_return_20d` ‚Äî –ø—Ä–æ–≥–Ω–æ–∑ –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ –Ω–∞ 20 –¥–Ω–µ–π
- `pred_prob_up_1d` ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –∑–∞ 1 –¥–µ–Ω—å (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ sigmoid)
- `pred_prob_up_20d` ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–æ—Å—Ç–∞ –∑–∞ 20 –¥–Ω–µ–π (–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ sigmoid)

**–ú–µ—Ç—Ä–∏–∫–∞:**
```
Score = MAE (Mean Absolute Error)
```
–≥–¥–µ:
- `MAE` = Mean Absolute Error –¥–ª—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏ (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
- –£—Å—Ä–µ–¥–Ω—è–µ—Ç—Å—è –ø–æ –æ–±–æ–∏–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–º (1d –∏ 20d)

**–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:**
- –¶–µ–Ω—ã –¥–æ—Å—Ç—É–ø–Ω—ã –¥–æ `t` –≤–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–æ
- –ù–æ–≤–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–æ `t-1` (–∑–∞–¥–µ—Ä–∂–∫–∞ 1 –¥–µ–Ω—å)
- –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã train+predict ‚â§ 60 –º–∏–Ω—É—Ç
- –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å: —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π seed

**–†–µ—Ñ–µ—Ä–µ–Ω—Å:** `scripts/baseline_solution.py` ‚Äî –ø—Ä–æ—Å—Ç–æ–π momentum-based –ø–æ–¥—Ö–æ–¥

---

## üèóÔ∏è –¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ src/finam/

–ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –±–µ–∑ –∏–∑–ª–∏—à–Ω–µ–π –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç–∏:

```
src/finam/
‚îú‚îÄ‚îÄ __init__.py           # package marker
‚îú‚îÄ‚îÄ metrics.py            # MAE, Brier, DA, normalized scores
‚îú‚îÄ‚îÄ features.py           # technical indicators (momentum, volatility, MA, RSI, MACD, etc)
‚îú‚îÄ‚îÄ features_news.py      # ‚ú® NEWS features (counts —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º lag)
‚îú‚îÄ‚îÄ model.py              # model wrapper (MomentumBaseline, LightGBMModel)
‚îú‚îÄ‚îÄ evaluate.py           # model comparison utilities
‚îî‚îÄ‚îÄ cv.py                 # cross-validation (rolling window –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤)
```

### –û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥—É–ª–µ–π

**metrics.py** ‚Äî —Ä–∞—Å—á—ë—Ç –º–µ—Ç—Ä–∏–∫ (—Ç–æ–ª—å–∫–æ MAE)
```python
def mae(y_true, y_pred) -> float
def evaluate_predictions(y_true_1d, y_true_20d, pred_1d, pred_20d) -> dict
def print_metrics(metrics: dict, model_name: str) -> None
```

**features.py** ‚Äî –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
```python
def compute_momentum(df: pd.DataFrame, window: int = 5) -> pd.DataFrame
def compute_volatility(df: pd.DataFrame, window: int = 5) -> pd.DataFrame
def compute_moving_average(df: pd.DataFrame, window: int = 5) -> pd.DataFrame
def add_all_features(df: pd.DataFrame, windows: list[int] = [5, 20]) -> pd.DataFrame
```
> –†–µ—Ñ–µ—Ä–µ–Ω—Å: `scripts/baseline_solution.py:60-96`

**model.py** ‚Äî –æ–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ –º–æ–¥–µ–ª—è–º–∏ (—Ç–æ–ª—å–∫–æ regression)
```python
class BaseModel:
    def fit(X, y_return_1d, y_return_20d) -> None
    def predict(X) -> dict  # returns {pred_return_1d, pred_return_20d}

class MomentumBaseline(BaseModel):  # baseline –∏–∑ scripts/
class LightGBMModel(BaseModel):     # 2 regression –º–æ–¥–µ–ª–∏ (MAE loss)
```

**pipeline.py** ‚Äî train/predict workflow
```python
def train_pipeline(train_candles_path, output_model_path, **kwargs) -> None
def predict_pipeline(test_candles_path, model_path, output_submission_path) -> None
```

**cv.py** ‚Äî –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
```python
def rolling_cv_split(df: pd.DataFrame, n_splits: int = 5, test_size: int = 20) -> Iterator
def evaluate_model_cv(model, df: pd.DataFrame, cv_splitter) -> dict[str, float]
```

---

## üöÄ Workflow –¥–ª—è LLM –∞–≥–µ–Ω—Ç–∞

### 1. Analyze (–ê–Ω–∞–ª–∏–∑ –∑–∞–¥–∞—á–∏)
- –ü—Ä–æ—á–∏—Ç–∞—Ç—å baseline –≤ `scripts/baseline_solution.py`
- –ü–æ–Ω—è—Ç—å —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö, –º–µ—Ç—Ä–∏–∫–∏, pipeline
- –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å scope –∏–∑–º–µ–Ω–µ–Ω–∏–π

### 2. Plan (–°–æ—Å—Ç–∞–≤–∏—Ç—å –ø–ª–∞–Ω)
```
1. –ö–∞–∫—É—é –≥–∏–ø–æ—Ç–µ–∑—É –ø—Ä–æ–≤–µ—Ä—è–µ–º?
2. –ö–∞–∫–æ–π –º–æ–¥—É–ª—å —Å–æ–∑–¥–∞—ë–º/–º–µ–Ω—è–µ–º?
3. –ö–∞–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–±–∞–≤–ª—è–µ–º?
4. –ö–∞–∫ –∏–∑–º–µ—Ä–∏–º —É–ª—É—á—à–µ–Ω–∏–µ?
```

### 3. Code (–†–µ–∞–ª–∏–∑–∞—Ü–∏—è)
- –°–æ–∑–¥–∞—Ç—å/–∏–∑–º–µ–Ω–∏—Ç—å –æ–¥–∏–Ω —Ñ–∞–π–ª –∑–∞ —Ä–∞–∑
- –Ø–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—É–Ω–∫—Ü–∏–π (–Ω–µ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥–∏)
- –ü—Ä–æ—Å—Ç—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã (pandas DataFrames in/out)
- –î–æ–±–∞–≤–∏—Ç—å docstrings —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏

### 4. Test (–ü—Ä–æ–≤–µ—Ä–∫–∞)
```bash
# Lint –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
ruff check --fix src/ && ruff format src/

# –ó–∞–ø—É—Å—Ç–∏—Ç—å baseline –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
python scripts/baseline_solution.py

# –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–≤–æ–π –∫–æ–¥ (–∫–æ–≥–¥–∞ –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤)
python -m src.finam.pipeline train ...
python -m src.finam.pipeline predict ...
```

### 5. Document (–ó–∞–ø–∏—Å—å –≤ SESSION.md)
```
## 2025-10-03: –î–æ–±–∞–≤–∏–ª –º–æ–¥—É–ª—å features.py
- –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è momentum, volatility, MA
- –ë–∞–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ scripts/baseline_solution.py:60-96
- –ì–æ—Ç–æ–≤–æ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ pipeline
```

---

## ‚ö° Golden Rules –¥–ª—è –•–∞–∫–∞—Ç–æ–Ω–∞

### 1. –ü—Ä–æ—Å—Ç–æ—Ç–∞ > –°–ª–æ–∂–Ω–æ—Å—Ç—å
```python
# ‚úÖ GOOD: –Ø–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
def compute_momentum(df: pd.DataFrame, window: int = 5) -> pd.DataFrame:
    return df.groupby('ticker')['close'].pct_change(window)

# ‚ùå BAD: –°–∫—Ä—ã—Ç—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
def compute_momentum(df: pd.DataFrame):
    window = CONFIG['features']['momentum_window']  # –æ—Ç–∫—É–¥–∞ CONFIG?
    ...
```

### 2. Baseline First
- –°–Ω–∞—á–∞–ª–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ baseline –∏–∑ scripts/
- –ü–æ—Ç–æ–º –¥–æ–±–∞–≤–ª—è—Ç—å —É–ª—É—á—à–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É
- –ò–∑–º–µ—Ä—è—Ç—å –∫–∞–∂–¥–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ

### 3. Explicit > Implicit
```python
# ‚úÖ GOOD: –ü–æ–Ω—è—Ç–Ω–æ —á—Ç–æ –Ω–∞ –≤—Ö–æ–¥–µ/–≤—ã—Ö–æ–¥–µ
def train_model(train_df: pd.DataFrame, feature_cols: list[str],
                target_col: str = 'return_1d') -> BaseModel:
    ...

# ‚ùå BAD: –ù–µ—è—Å–Ω–æ —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç
def train_model(cfg):  # —á—Ç–æ –≤ cfg? –∫–∞–∫–∏–µ –ø–æ–ª—è? –∫–∞–∫–∏–µ —Ç–∏–ø—ã?
    ...
```

### 4. –ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å
```bash
# –ß–∞—Å—Ç—ã–µ –∫–æ–º–º–∏—Ç—ã —Å –º–∞–ª–µ–Ω—å–∫–∏–º–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è–º–∏
git add src/finam/metrics.py
git commit -m "feat: add MAE and Brier metrics"

# –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
ruff check src/ && python -m pytest tests/ -q
```

### 5. Colab Compatibility
```python
# ‚úÖ GOOD: –†–∞–±–æ—Ç–∞–µ—Ç –≤ Colab
!pip install git+https://github.com/user/finam.git
from finam.model import LightGBMModel
from finam.features import add_all_features

# ‚úÖ GOOD: Minimal dependencies
# pandas, numpy, scikit-learn ‚Äî —É–∂–µ –≤ Colab
# lightgbm, joblib, pyyaml ‚Äî –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–µ
```

---

## üîß –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç –≤ Colab
```python
# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞
!pip install git+https://github.com/your-repo/finam.git

# 2. –ò–º–ø–æ—Ä—Ç—ã
from finam.features import add_all_features
from finam.model import MomentumBaseline
from finam.metrics import mae, brier_score, normalized_score

# 3. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
import pandas as pd
train_df = pd.read_csv('train_candles.csv')
test_df = pd.read_csv('test_candles.csv')

# 4. Feature engineering
train_df = add_all_features(train_df, windows=[5, 20])
test_df = add_all_features(test_df, windows=[5, 20])

# 5. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–∞—Ä–≥–µ—Ç–æ–≤
X_train = train_df[feature_cols]
y_return_1d = train_df['target_return_1d'].values
y_return_20d = train_df['target_return_20d'].values

# 6. Train (—Ç–æ–ª—å–∫–æ regression –¥–ª—è MAE)
model = LightGBMModel()
model.fit(X_train, y_return_1d, y_return_20d)

# 7. Predict
X_test = test_df[feature_cols]
predictions = model.predict(X_test)  # {pred_return_1d, pred_return_20d}

# 8. Evaluate
from finam.metrics import evaluate_predictions
metrics = evaluate_predictions(
    y_true_1d, y_true_20d,
    predictions['pred_return_1d'],
    predictions['pred_return_20d']
)
print(f"MAE 1d: {metrics['mae_1d']:.6f}")
print(f"MAE 20d: {metrics['mae_20d']:.6f}")
print(f"MAE mean: {metrics['mae_mean']:.6f}")
```

---

## üö´ –ê–Ω—Ç–∏-–ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –•–∞–∫–∞—Ç–æ–Ω–∞

### ‚ùå –ù–µ –¥–µ–ª–∞—Ç—å:
- **Hydra configs** ‚Äî —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞
- **–ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ –∞–±—Å—Ç—Ä–∞–∫—Ü–∏–∏** ‚Äî core/formatting/orchestration –∏–∑–ª–∏—à–Ω–∏
- **Pydantic models** ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø—Ä–æ—Å—Ç—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π —Å —Ç–∏–ø–∞–º–∏
- **–°–ª–æ–∂–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤** ‚Äî –¥–µ—Ä–∂–∏–º flat hierarchy
- **OOP –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏** ‚Äî —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ—â–µ –¥–ª—è Jupyter/Colab

### ‚úÖ –î–µ–ª–∞—Ç—å:
- **–§—É–Ω–∫—Ü–∏–∏ —Å —è–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏** ‚Äî –ª–µ–≥–∫–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –Ω–æ—É—Ç–±—É–∫–µ
- **–û–¥–∏–Ω —Ñ–∞–π–ª = –æ–¥–Ω–∞ –∑–∞–¥–∞—á–∞** ‚Äî metrics, features, model –æ—Ç–¥–µ–ª—å–Ω–æ
- **Pandas in/out** ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è data science
- **–ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏–º–µ—Ä—ã –≤ docstrings** ‚Äî –ø–æ–Ω—è—Ç–Ω–æ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
- **–ò–∑–º–µ—Ä–∏–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è** ‚Äî –∫–∞–∂–¥–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ = —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏

---

## üìö –†–µ—Ñ–µ—Ä–µ–Ω—Å—ã

**Baseline —Ä–µ—à–µ–Ω–∏–µ:**
`scripts/baseline_solution.py` ‚Äî momentum-based –ø–æ–¥—Ö–æ–¥ (–ø—Ä–æ—Å—Ç–æ–π, —Ä–∞–±–æ—Ç–∞–µ—Ç, –º–æ–∂–Ω–æ —É–ª—É—á—à–∞—Ç—å)

**–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –∑–∞–¥–∞—á–∏:**
- `docs/task.md` ‚Äî –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∑–∞–¥–∞—á–∏ FORECAST
- `docs/evaluation.md` ‚Äî –º–µ—Ç—Ä–∏–∫–∏ –∏ —Ñ–æ—Ä–º—É–ª—ã –æ—Ü–µ–Ω–∫–∏
- `docs/data.md` ‚Äî —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å)

**Quality gates:**
```bash
ruff check --fix src/ tests/
ruff format src/ tests/
```

**–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ:**
- `SESSION.md` ‚Äî –∫—Ä–∞—Ç–∫–∏–µ –∑–∞–ø–∏—Å–∏ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ (append only)
- `TODO.md` ‚Äî —Ç–µ–∫—É—â–∏–µ –∑–∞–¥–∞—á–∏ (gitignored, –¥–ª—è –∂–∏–≤–æ–π —Ä–∞–±–æ—Ç—ã)

---

## üéì –î–ª—è –∞–≥–µ–Ω—Ç–∞: —Å—Ç—Ä–∞—Ç–µ–≥–∏—è —É–ª—É—á—à–µ–Ω–∏—è baseline

### –ò—Ç–µ—Ä–∞—Ü–∏—è 1: –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å
1. –ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ baseline –∏–∑ scripts/ –≤ src/finam/
2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –ø–æ–ª—É—á–∞—é—Ç—Å—è —Ç–µ –∂–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
3. –î–æ–±–∞–≤–∏—Ç—å —Ç–µ—Å—Ç—ã –Ω–∞ –º–µ—Ç—Ä–∏–∫–∏

### –ò—Ç–µ—Ä–∞—Ü–∏—è 2: Feature Engineering
1. –î–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ (RSI, MACD, Bollinger Bands)
2. –î–æ–±–∞–≤–∏—Ç—å lag features –¥–ª—è —Ü–µ–Ω
3. Cross-ticker features (sector momentum, market regime)

### –ò—Ç–µ—Ä–∞—Ü–∏—è 3: Simple ML
1. Linear Regression / Ridge –¥–ª—è –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
2. LightGBM –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
3. Ensemble (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –º–æ–¥–µ–ª—è–º)

### –ò—Ç–µ—Ä–∞—Ü–∏—è 4: Cross-Validation
1. Rolling window CV –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
2. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–∞—Ö

### –ò—Ç–µ—Ä–∞—Ü–∏—è 5: News Integration ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**features_news.py** ‚Äî –Ω–æ–≤–æ—Å—Ç–Ω—ã–µ —Ñ–∏—á–∏ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º lag

```python
def compute_daily_news_count(news_df, date_col='publish_date') -> pd.DataFrame
def add_news_features(candles_df, news_df, lag_days=1, rolling_windows=[1, 7, 30]) -> pd.DataFrame
```

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏—á–∏:**
- `news_count_1d_lag` ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–µ–Ω—å
- `news_count_7d_lag` ‚Äî –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π (—Å –ª–∞–≥–æ–º)
- `news_count_30d_lag` ‚Äî –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π (—Å –ª–∞–≥–æ–º)

**‚ö†Ô∏è –í–ê–ñ–ù–û: Data Leakage Protection**
- –ù–æ–≤–æ—Å—Ç–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –¥–æ `t-1` (–∑–∞–¥–µ—Ä–∂–∫–∞ 1 –¥–µ–Ω—å)
- –î–ª—è —Å–≤–µ—á–µ–π –¥–Ω—è `t` –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –¥–æ `t-lag_days`
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–¥–≤–∏–≥ –¥–∞—Ç –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –¥–∂–æ–π–Ω–∞

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**
- ‚úÖ Feature importance: —Ç–æ–ø-2 –ø—Ä–∏–∑–Ω–∞–∫–∞
- ‚úÖ –£–ª—É—á—à–µ–Ω–∏–µ MAE vs Momentum baseline

**–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:**
1. Sentiment analysis (VADER, FinBERT)
2. Topic modeling (LDA, BERTopic)
3. Entity extraction (–∫–∞–∫–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ —É–ø–æ–º–∏–Ω–∞—é—Ç—Å—è)
4. Weighted average sentiment –ø–æ —Ç–∏–∫–µ—Ä–∞–º

---

### –ò—Ç–µ—Ä–∞—Ü–∏—è 6: –£–ø—Ä–æ—â–µ–Ω–∏–µ –ø–æ–¥ MAE ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–¶–µ–ª—å:** –£–ø—Ä–æ—Å—Ç–∏—Ç—å –ø—Ä–æ–µ–∫—Ç, —É–±—Ä–∞–≤ Brier Score, DA –∏ –∫–∞–ª–∏–±—Ä–æ–≤–∫—É.

**–ò–∑–º–µ–Ω–µ–Ω–∏—è:**
- –£–¥–∞–ª–µ–Ω—ã classification –º–æ–¥–µ–ª–∏ (prob_up_*)
- –£–¥–∞–ª–µ–Ω –∫–ª–∞—Å—Å `CalibratedLightGBMModel`
- –£–ø—Ä–æ—â–µ–Ω—ã –º–µ—Ç—Ä–∏–∫–∏: —Ç–æ–ª—å–∫–æ MAE –¥–ª—è 1d –∏ 20d
- `pred_prob_up_*` –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —á–µ—Ä–µ–∑ sigmoid –≤ submission –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º
- –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è: —Ç–æ–ª—å–∫–æ 2 —Ä–µ–≥—Ä–µ—Å—Å–æ—Ä–∞ –≤–º–µ—Å—Ç–æ 4 –º–æ–¥–µ–ª–µ–π

**–†–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ –£–ø—Ä–æ—â–µ–Ω–∏–µ –∫–æ–¥–∞ –Ω–∞ ~40%
- ‚úÖ –§–æ–∫—É—Å –Ω–∞ –≥–ª–∞–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ (MAE)
- ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å submission —Ñ–æ—Ä–º–∞—Ç–æ–º

---

**–ì–ª–∞–≤–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ:** –ö–∞–∂–¥–∞—è –∏—Ç–µ—Ä–∞—Ü–∏—è = +1 –≥–∏–ø–æ—Ç–µ–∑–∞, +–∫–æ–¥, +–º–µ—Ç—Ä–∏–∫–∏. –ë–µ–∑ –º–µ—Ç—Ä–∏–∫ = –Ω–µ —Å—á–∏—Ç–∞–µ—Ç—Å—è.

–£–¥–∞—á–∏! üöÄ
